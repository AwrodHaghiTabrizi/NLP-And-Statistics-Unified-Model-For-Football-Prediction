{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardian_dataset_dir = f\"../datasets/Guardian_Dataset.csv\"\n",
    "df = pd.read_csv(guardian_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The consensus suggests this will be Antonio Conte’s last Premier League game in charge of Chelsea. Can he use it to somehow secure a top-four finish? Newcastle fans must trust this is not Rafael Benítez’s Tyneside swansong. The negotiations between their widely coveted manager and Mike Ashley over extending a contract that has only a year to run remain delicate. Expect the Gallowgate End to, not for the first time, repeatedly sing “Rafa Benítez, we want you to stay.” Chelsea meanwhile are monitoring Newcastle’s much improved centre-half Jamaal Lascelles. He could be key to Benítez’s team ending a run of four straight defeats as they struggle to retain their grip on 10th place. Louise Taylor\n"
     ]
    }
   ],
   "source": [
    "row_1_text = df.loc[1, 'Text']\n",
    "print(row_1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Awrod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Awrod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1): The consensus suggests this will be Antonio Conte’s last Premier League game in charge of Chelsea.\n",
      "2): Can he use it to somehow secure a top-four finish?\n",
      "3): Newcastle fans must trust this is not Rafael Benítez’s Tyneside swansong.\n",
      "4): The negotiations between their widely coveted manager and Mike Ashley over extending a contract that has only a year to run remain delicate.\n",
      "5): Expect the Gallowgate End to, not for the first time, repeatedly sing “Rafa Benítez, we want you to stay.” Chelsea meanwhile are monitoring Newcastle’s much improved centre-half Jamaal Lascelles.\n",
      "6): He could be key to Benítez’s team ending a run of four straight defeats as they struggle to retain their grip on 10th place.\n",
      "7): Louise Taylor\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(row_1_text)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"{i+1}): {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Awrod\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\Awrod\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# model = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-2.7B\")\n",
    "# model = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-2.7B\", device=0)\n",
    "# model = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-1.3B\", device=0)\n",
    "model = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-2.7B\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "\n",
      "\n",
      "You will be given a sentence extracted from a preview of a football match.\n",
      "The home team is Newcastle United and the away team is Chelsea.\n",
      "Please classify which team the sentence is talking about by responding with only one word: 'home', 'away', 'both', or 'neither'.\n",
      "The sentence you need to classify is: The consensus suggests this will be Antonio Conte’s last Premier League game in charge of Chelsea.\n",
      "\n",
      "A:\n",
      "\n",
      "I can easily think up\n"
     ]
    }
   ],
   "source": [
    "home_team = df.loc[1, 'Home']\n",
    "away_team = df.loc[1, 'Away']\n",
    "\n",
    "# prompt_text = f\"\"\"\n",
    "# You will be given a setence that is extracted from a preview of a football match.\n",
    "# The home team is {home_team} and the away team is {away_team}.\n",
    "# Classify which team the sentence is talking about.\n",
    "# All you must do is respond 'home', 'away', 'both', or 'neither'.\n",
    "# The sentence you need to classify is: {sentences[0]}\n",
    "# \"\"\"\n",
    "prompt_text = f\"\"\"\n",
    "You will be given a sentence extracted from a preview of a football match.\n",
    "The home team is {home_team} and the away team is {away_team}.\n",
    "Please classify which team the sentence is talking about by responding with only one word: 'home', 'away', 'both', or 'neither'.\n",
    "The sentence you need to classify is: {sentences[0]}\n",
    "\"\"\"\n",
    "# response = model((prompt_text), max_length=150, num_return_sequences=1)\n",
    "response = model((prompt_text), max_new_tokens=10, num_return_sequences=1)\n",
    "print(\"\\n\\nResponse:\\n\\n\")\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\", padding_side='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "\n",
    "for step in range(5):\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "\n",
    "QA_input = {\n",
    "    'question': 'Why is model conversion important?',\n",
    "    'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\n",
    "}\n",
    "print(nlp(QA_input))\n",
    "\n",
    "QA_input = {\n",
    "    'question': 'Why is a good programming language?',\n",
    "    'context': 'For robotics.'\n",
    "}\n",
    "print(nlp(QA_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "distilled_student_sentiment_classifier = pipeline(\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "distilled_student_sentiment_classifier(\"This team is obviously going to lose.\")\n",
    "distilled_student_sentiment_classifier(\"There have been a change in management.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import SetFitModel, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Define your few-shot samples\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"The players are tired from the previous game\",\n",
    "        \"There is a change in management\",\n",
    "        \"The players are cheerful from winning a close one last week\"\n",
    "    ],\n",
    "    \"label\": [\n",
    "        \"negative\",  # Class for first sample\n",
    "        \"negative\",  # Class for second sample\n",
    "        \"Positive\"   # Class for third sample\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a dataset from the few-shot samples\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Map text labels to integers (required for training)\n",
    "label_mapping = {\"Positive\": 0, \"negative\": 1, \"neutral\": 2}\n",
    "dataset = dataset.map(lambda x: {\"label\": label_mapping[x[\"label\"]]})\n",
    "\n",
    "# Load a pretrained SetFit model\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "\n",
    "# Train the model using the few-shot dataset\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    metric=\"accuracy\"\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Use the trained model for inference\n",
    "predictions = model([\"The team is hopeful about their upcoming match\"])\n",
    "predicted_label = [list(label_mapping.keys())[label] for label in predictions]\n",
    "\n",
    "print(predicted_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
