{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardian_dataset_dir = f\"../datasets/Guardian_Dataset.csv\"\n",
    "df = pd.read_csv(guardian_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The consensus suggests this will be Antonio Conte’s last Premier League game in charge of Chelsea. Can he use it to somehow secure a top-four finish? Newcastle fans must trust this is not Rafael Benítez’s Tyneside swansong. The negotiations between their widely coveted manager and Mike Ashley over extending a contract that has only a year to run remain delicate. Expect the Gallowgate End to, not for the first time, repeatedly sing “Rafa Benítez, we want you to stay.” Chelsea meanwhile are monitoring Newcastle’s much improved centre-half Jamaal Lascelles. He could be key to Benítez’s team ending a run of four straight defeats as they struggle to retain their grip on 10th place. Louise Taylor\n"
     ]
    }
   ],
   "source": [
    "row_1_text = df.loc[1, 'Text']\n",
    "print(row_1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Awrod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Awrod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1): The consensus suggests this will be Antonio Conte’s last Premier League game in charge of Chelsea.\n",
      "2): Can he use it to somehow secure a top-four finish?\n",
      "3): Newcastle fans must trust this is not Rafael Benítez’s Tyneside swansong.\n",
      "4): The negotiations between their widely coveted manager and Mike Ashley over extending a contract that has only a year to run remain delicate.\n",
      "5): Expect the Gallowgate End to, not for the first time, repeatedly sing “Rafa Benítez, we want you to stay.” Chelsea meanwhile are monitoring Newcastle’s much improved centre-half Jamaal Lascelles.\n",
      "6): He could be key to Benítez’s team ending a run of four straight defeats as they struggle to retain their grip on 10th place.\n",
      "7): Louise Taylor\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(row_1_text)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"{i+1}): {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zero-shot-classification <br> model=facebook/bart-large-mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"There has been a change in management.\"\n",
    "polarity_labels = [\"positive\", \"neutral\", \"negative\"]\n",
    "tone_labels = [\"factual\", \"opinionated\"]\n",
    "print(classifier(text, polarity_labels))\n",
    "print(classifier(text, tone_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-2.7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt = (\n",
    "    \"In the context of sports, classify the following text into one of these categories: positive, neutral, negative.\\n\"\n",
    "    \"Text: 'There has been a change in management.'\\n\"\n",
    "    \"Category:\"\n",
    ")\n",
    "response = model(prompt, max_length=50, num_return_sequences=1)\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\", padding_side='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "\n",
    "for step in range(5):\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "\n",
    "QA_input = {\n",
    "    'question': 'Why is model conversion important?',\n",
    "    'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\n",
    "}\n",
    "print(nlp(QA_input))\n",
    "\n",
    "QA_input = {\n",
    "    'question': 'Why is a good programming language?',\n",
    "    'context': 'For robotics.'\n",
    "}\n",
    "print(nlp(QA_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "distilled_student_sentiment_classifier = pipeline(\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "distilled_student_sentiment_classifier(\"This team is obviously going to lose.\")\n",
    "distilled_student_sentiment_classifier(\"There have been a change in management.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import SetFitModel, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Define your few-shot samples\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"The players are tired from the previous game\",\n",
    "        \"There is a change in management\",\n",
    "        \"The players are cheerful from winning a close one last week\"\n",
    "    ],\n",
    "    \"label\": [\n",
    "        \"negative\",  # Class for first sample\n",
    "        \"negative\",  # Class for second sample\n",
    "        \"Positive\"   # Class for third sample\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a dataset from the few-shot samples\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Map text labels to integers (required for training)\n",
    "label_mapping = {\"Positive\": 0, \"negative\": 1, \"neutral\": 2}\n",
    "dataset = dataset.map(lambda x: {\"label\": label_mapping[x[\"label\"]]})\n",
    "\n",
    "# Load a pretrained SetFit model\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "\n",
    "# Train the model using the few-shot dataset\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    metric=\"accuracy\"\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Use the trained model for inference\n",
    "predictions = model([\"The team is hopeful about their upcoming match\"])\n",
    "predicted_label = [list(label_mapping.keys())[label] for label in predictions]\n",
    "\n",
    "print(predicted_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
