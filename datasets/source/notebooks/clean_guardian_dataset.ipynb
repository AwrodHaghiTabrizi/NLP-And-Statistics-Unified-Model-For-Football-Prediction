{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Guardian Dataset\n",
    "\n",
    "The Guardian datset containts match previews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardian_original_dataset_dir = f\"../original/Guardian_Dataset.csv\"\n",
    "\n",
    "with open(guardian_original_dataset_dir, 'rb') as f:\n",
    "    encoding = chardet.detect(f.read())['encoding']\n",
    "\n",
    "guardian_df = pd.read_csv(guardian_original_dataset_dir, encoding=encoding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize the team names in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_team_names_dir = f\"../resources/standardized_team_names.json\"\n",
    "with open(standardized_team_names_dir, 'r') as file:\n",
    "    standardized_team_names = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_team_name(name, standardized_names):\n",
    "    for standard_name, variations in standardized_names.items():\n",
    "        if name in variations:\n",
    "            return standard_name\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardian_df['Home'] = guardian_df['Home'].apply(lambda x: standardize_team_name(x, standardized_team_names))\n",
    "guardian_df['Away'] = guardian_df['Away'].apply(lambda x: standardize_team_name(x, standardized_team_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1 rows from dataset, reducing size by 0.07%\n"
     ]
    }
   ],
   "source": [
    "nan_row_count = guardian_df.isna().any(axis=1).sum()\n",
    "total_rows = len(guardian_df)\n",
    "\n",
    "guardian_df = guardian_df.dropna()\n",
    "\n",
    "nan_row_count_after_drop = guardian_df.isna().any(axis=1).sum()\n",
    "total_rows_after_drop = len(guardian_df)\n",
    "\n",
    "if nan_row_count != total_rows - total_rows_after_drop:\n",
    "    raise(\"Error: NaN values were not removed.\")\n",
    "elif nan_row_count_after_drop != 0:\n",
    "    raise(\"Error: NaN values still present.\")\n",
    "\n",
    "print(f\"Removed {nan_row_count} rows from dataset, reducing size by {nan_row_count/total_rows*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardian_dataset_cleaned_dir = f\"../processed/Guardian_Dataset_Cleaned.csv\"\n",
    "guardian_df.to_csv(guardian_dataset_cleaned_dir, index=False, encoding=encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
